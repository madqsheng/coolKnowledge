# 概述

根据机器学习（深度学习）分类损失函数

1. 回归 **regression**
2. 分类 **classification**
3. 排名 **Ranking**
   - 为一组项目（例如搜索结果、推荐项、文档、商品等）确定它们的相对顺序，以便将最相关或最相关的项目排在前面。
   - 包括：**搜索引擎排名，推荐系统，自然语言处理中文档搜索，摘要生成，在线广告和广告点击率预测，排名竞赛**
4. 样本生成 **sample generation**
   - 生成符合特定分布或条件的新样本
   - 包括：**生成模型、数据增强、生成对抗网络（GANs）、强化学习、自然语言处理中的生成文章、对话、摘要、噪音注入等**
5. **Energy-based models（EBMs）**
   - 为数据点分配一个能量或分数，然后根据这些分数来进行不同的任务
   - EBMs的核心思想是，模型会为真实数据分配较低的能量，而为生成的或异常数据分配较高的能量。
   - EBMs通常通过训练模型参数以最小化正常数据的能量分数并最大化异常数据的能量分数来学习。这使得模型能够将正常数据分离出来，并为异常数据分配较高的能量。在不同任务中，EBMs的具体形式和训练过程可能会有所不同，但它们都依赖于建立一个能量函数，以衡量数据点的"质量"或异常性。
   - 包括：
     - **异常检测（Anomaly Detection）：** 在异常检测任务中，EBMs可用于识别与正常样本不同的异常样本。模型为正常样本分配较低的能量分数，而为异常样本分配较高的能量分数。通过比较能量分数，可以识别异常样本。
     - **密度估计（Density Estimation）：** EBMs可以用于估计数据分布的密度。模型学会将高概率密度分配给真实数据点，低概率密度分配给不常见的或异常数据点。
     - **生成对抗网络（GANs）：** 在生成对抗网络中，判别器可以被看作是一个EBM。判别器的任务是为真实数据和生成的数据分配能量分数，以帮助生成器生成更逼真的样本。
     - **变分推断（Variational Inference）：** 在变分推断中，EBMs可以用于构建变分自动编码器（Variational Autoencoders, VAEs）中的能量模型，以帮助学习数据的潜在表示。
     - **无监督学习（Unsupervised Learning）：** EBMs可以用于学习数据的表示或特征，尤其是在没有明确的标签信息的情况下。
     - **半监督学习（Semi-Supervised Learning）：** EBMs可以结合标记数据和未标记数据来改进半监督学习任务的性能。

- 分类

![损失函数](..\示例图片\损失函数.png)

