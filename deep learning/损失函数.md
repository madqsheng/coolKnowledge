# 概述

根据机器学习（深度学习）分类损失函数

1. 回归 **regression**
2. 分类 **classification**
3. 排名 **Ranking**
   - 为一组项目（例如搜索结果、推荐项、文档、商品等）确定它们的相对顺序，以便将最相关或最相关的项目排在前面。
   - 包括：**搜索引擎排名，推荐系统，自然语言处理中文档搜索，摘要生成，在线广告和广告点击率预测，排名竞赛**
4. 样本生成 **sample generation**
   - 生成符合特定分布或条件的新样本
   - 包括：**生成模型、数据增强、生成对抗网络（GANs）、强化学习、自然语言处理中的生成文章、对话、摘要、噪音注入等**
5. **Energy-based models（EBMs）**
   - 为数据点分配一个能量或分数，然后根据这些分数来进行不同的任务
   - EBMs的核心思想是，模型会为真实数据分配较低的能量，而为生成的或异常数据分配较高的能量。
   - EBMs通常通过训练模型参数以最小化正常数据的能量分数并最大化异常数据的能量分数来学习。这使得模型能够将正常数据分离出来，并为异常数据分配较高的能量。在不同任务中，EBMs的具体形式和训练过程可能会有所不同，但它们都依赖于建立一个能量函数，以衡量数据点的"质量"或异常性。
   - 包括：
     - **异常检测（Anomaly Detection）：** 在异常检测任务中，EBMs可用于识别与正常样本不同的异常样本。模型为正常样本分配较低的能量分数，而为异常样本分配较高的能量分数。通过比较能量分数，可以识别异常样本。
     - **密度估计（Density Estimation）：** EBMs可以用于估计数据分布的密度。模型学会将高概率密度分配给真实数据点，低概率密度分配给不常见的或异常数据点。
     - **生成对抗网络（GANs）：** 在生成对抗网络中，判别器可以被看作是一个EBM。判别器的任务是为真实数据和生成的数据分配能量分数，以帮助生成器生成更逼真的样本。
     - **变分推断（Variational Inference）：** 在变分推断中，EBMs可以用于构建变分自动编码器（Variational Autoencoders, VAEs）中的能量模型，以帮助学习数据的潜在表示。
     - **无监督学习（Unsupervised Learning）：** EBMs可以用于学习数据的表示或特征，尤其是在没有明确的标签信息的情况下。
     - **半监督学习（Semi-Supervised Learning）：** EBMs可以结合标记数据和未标记数据来改进半监督学习任务的性能。

## 分类

![损失函数](..\示例图片\损失函数.png)

## 损失函数表达式

1. 模型定义
   $$
   f:Φ→γ
   $$
   其中`f`是模型的函数表达式，$f_Θ$代表模型，参数是$Θ$

2. 损失函数定义

   **模型的预测与实际目标之间的差异**：$L((f(\pmb{x_i})),y_i)$

3. 总体损失

   给定输入集合$\{\mathbf{x_0},...,\pmb{x_n}\}∈Φ$，输出$\{y_0,...,y_n\}∈γ$
   $$
   ￡(f|\{\mathbf{x_0},...,\pmb{x_n}\},\{y_0,...,y_n\})=
   \frac{1}{N}\sum_{i=1}^{N}L((f(\pmb{x_i})),y_i)
   $$

## 损失函数数学性质

1. 连续性 Continuity
2. 可微 Differentiability 
3. 凸性 Convexity

# 1. Regression

## 1.1 MBE(Mean Bias Error Loss)

$$
￡_{MBE}=
\frac{1}{N}\sum_{i=1}^{N}y_i-f(\pmb{x_i})
$$

- **连续、可微**
- 实际很少作为损失函数，因为**正向和负向的误差可能会互相抵消**，带来潜在的参数估计错误

## 1.2 MAE(Mean Absolute Error Loss)

$$
￡_{MAE}=
\frac{1}{N}\sum_{i=1}^{N}|y_i-f(\pmb{x_i})|
$$

- **凸性**
- 克服MBE的误差抵消的问题
- 但是**大误差和小误差的重要性相同**，导致**误差小的时候，难收敛**

## 1.3 MSE( Mean Squared Error Loss)

$$
￡_{MSE}=
\frac{1}{N}\sum_{i=1}^{N}(y_i-f(\pmb{x_i}))^2
$$

- **连续、可微、凸性**
- 克服MAE的大小误差重要性相同的问题
- 但是大误差的权重给的太大了，因此会导致对大误差数据（异常值outliers）很敏感

## 1.4 RMSE(Root Mean Squared Error Loss)

$$
￡_{RMSE}=\sqrt{
\frac{1}{N}\sum_{i=1}^{N}(y_i-f(\pmb{x_i}))^2}
$$

- **连续、可微、凸性**
- 和MSE没有太大区别
- 通常还是作为模型评估标准

## 1.5  Huber loss

$$
￡_{Huberloss} = 
\begin{cases}
    \frac{1}{2}(y_i-f(\pmb{x_i}))^2, & \text{if } |y_i-f(\pmb{x_i})|\leq \delta \\
    \delta(|y_i-f(\pmb{x_i})|-\frac{1}{2}\delta), & \text{otherwise} 
\end{cases}
$$

- **可微**
- **误差小用MSE，收敛很快**
- 误差大用MAE，异常值不会很敏感
- 额外超参量

## 4.6 Log-cosh loss

$$
￡_{logcosh}=
\frac{1}{N}\sum_{i=1}^{N}log(cosh(f(\pmb{x_i})-y_i))
$$

- **连续，可微**
- 包含Huber loss的所有优势，但没有超参量
- 计算代价大

## 4.7 Root Mean Squared Logarithmic Error Loss

$$
￡_{RMSLE}=\sqrt{
\frac{1}{N}\sum_{i=1}^{N}(log(y_i+1)-log(f(\pmb{x_i})+1))^2}
$$

- 连续、可微、凸性
- 对异常值更健壮（鲁棒）

# 2. Classification

- 分类

  1. margin based losses

     这类损失函数的核心在于边际间隔（margins），起核心在于促使模型产生更好的边际间隔（margins），从而提高模型的泛化性能。模型主要是支持向量机（**SVM**）

  2.  probabilistic losses

     以概率模型计算损失函数，原理有两个方面：

     - **极大似然估计**
     - **熵**

## 2.1 margin based losses

[SVM详解](https://zhuanlan.zhihu.com/p/49331510)

注意一点：**样本的真实类别标签通常为+1或-1**

### 2.1.1 零一损失Zero-One loss

$$
L_{ZeroOne}(f(\pmb{x}),y) = 
\begin{cases}
    1, & \text{if } f(\pmb{x})·y< 0\\
    0, & \text{otherwise} 
\end{cases}
$$

- **不可微、非凸性**

### 2.1.2 Hinge loss

$$
L_{Hinge}(f(\pmb{x}),y) = max(0,1-(f(\pmb{x})·y))
$$

- **非凸性**

### 2.1.3 Perceptron loss

$$
L_{Perceptron}(f(\pmb{x}),y) = max(0,-(f(\pmb{x})·y))
$$

- **非凸性**
- 对异常点敏感
- 不连续、不可微，难优化

### 2.1.4 Smoothed Hinge loss

$$
L_{Huberloss}(f(\pmb{x}),y) = 
\begin{cases}
    \frac{1}{2}-(f(\pmb{x})·t), & \text{if } (f(\pmb{x})·y)\leq 0 \\
    \frac{1}{2}(1-(f(\pmb{x})·t))^2, & \text{if } 0<(f(\pmb{x})·y)< 1 \\
    0, & \text{otherwise} 
\end{cases}
$$

- **可微**
- 易优化

### 2.1.5  Quadratically Smoothed Hinge loss

$$
L_{QSmoothedHinge}(f(\pmb{x}),y) = 
\begin{cases}
    \frac{1}{2\gamma}max(0,-(f(\pmb{x})·y))^2, & \text{if } (f(\pmb{x})·y)\ge 1-\gamma \\
    1-\frac{\gamma}{2}-(f(\pmb{x})·y), & \text{otherwise} 
\end{cases}
$$

- **可微、凸性**

### 2.1.6  Modified Huber loss

$$
L_{ModHuber}(f(\pmb{x}),y) = 
\begin{cases}
    \frac{1}{4}max(0,-(f(\pmb{x})·y))^2, & \text{if } (f(\pmb{x})·y)\ge -1 \\
    -(f(\pmb{x})·y), & \text{otherwise} 
\end{cases}
$$

- **可微**

### 2.1.7 Ramp loss

$$
L_{Ramp}(f(\pmb{x}),y) = 
\begin{cases}
    L_{Hinge}(f(\pmb{x}),y), & \text{if } (f(\pmb{x})·y)\leq 1 \\
    1, & \text{otherwise} 
\end{cases}
$$

- **凸性、连续**

### 2.1.8 Cosine Similarity loss

$$
L_{cos-sin}(f(\pmb{x}),y) = 1-\frac{f(\pmb{x})·y}{\|y\|\|f(\pmb{x})\|}
$$

- 可微

## 2.2 probabilistic losses

- 理论基础
  1. 极大似然估计
  2. 熵理论

### 2.2.1 极大似然估计MLE

- **Maximum likelihood estimation**

- **概率（probabilty）和统计（statistics）**是不同的领域，其实研究的问题刚好相反

  1. 概率研究的问题是，**已知一个模型和参数，怎么去预测这个模型产生结果的概率（例如均值，方差，协方差等等），或者基于先验知识求模型的概率律。**比如抛硬币的伯努利试验，**先验知识就是认为每次试验正反面概率是0.5**，可以以此为基础去研究抛100次出现40次的概率，数学期望等等。
  2. 统计研究的问题是，**通过大量样本数据去预测模型和参数**。比如某个地区的人的身高作为随机变量，满足什么概率律？没人能通过**先验知识**给出答案。**中心极限定理表明，样本足够多的时候，随机变量标准化以后满足标准正态分布**。那么问题来了，**随机变量标准化需要数学期望和方差，两者都是未知，**这时候就需要用到统计学的知识预估了，**随机变量的期望和方差就是模型的参数，知道了它们就能通过中心极限定理得到模型。**

  总结：**概率是已知模型和参数，计算概率和随机变量数字特征。统计是已知样本结果，推模型和参数**

- **似然函数和概率(密度)函数**
  $$
  P(x|\theta)
  $$
  **X**是随机变量，是随机变量的取值，$\theta$是模型参数

  - 概率函数：$\theta$已知，x是变量
  - 似然函数：x已知，$\theta$未知

  注意：==通常情况，模型用$f(\pmb{x})$表示，$\pmb{x}$是输入数据(向量)，但概率统计中x是随机变量取值，也就是随机试验的结果，其实对应是模型的输出$y=f(\pmb{x})$==，为了方便，上面函数写成：
  $$
  P(y|\theta)
  $$

- 极大似然估计

  - 定位：一种用于估计概率分布模型的参数的方法
  - 思想：**采集了许多样本值$y_0,...,y_n$，说明模型取到这些样本值的概率比较大。可以给出这些样本值的似然函数，相乘求最大值，就能得到估计的参数值**
  - 工作流：
    - 采集样本
    - 定义似然函数$P(y|\theta)$
    - 寻找最大似然函数估计
    - 解优化问题
    - 估计参数

  假设有一个造币厂生产某种硬币，目的是想知道这硬币是不是均匀的。想了一个办法，硬币均匀问题转移到抛硬币概率问题：我们已经有先验知识，**如果硬币均匀，抛硬币正面朝上的概率是0.5。**现在迫切想知道这个概率值是多少，**抛硬币正面朝上的概率，这本身就是模型的参数，也是唯一的参数。**

  按照上面的工作流:

  - **采集样本**：抛硬币10次，得到的数据是：反正正正正反正正正反。
  - **定义似然函数**：假设参数$\theta$是概率p，y正面为1，反面为0。这是一个二次分布，似然函数：$P(y|\theta)=p^y(1-p)^{1-y}$,10次数据代入进去，**总体似然函数**为：$(1-p)·p·p·p·p·(1-p)·p·p·p·(1-p)=p^7(1-p)^3$
  - **优化、估计参数**：p=0.7总体似然函数最大

- 扩展：**最大后验概率估计**

  - 定位：同样是一种用于估计概率分布模型的参数的方法

  - 思想：

    - 跟极大似然估计是一样的，不同在于最大化函数：
      $$
      P(\theta|y)=\frac{p(y\theta)}{p(y)}=\frac{f(y|\theta)·f(\theta)}{p(y)}
      $$

    - $p(y)$是根据样本确定的，比如前面抛硬币十次试验，$p(1)=0.7,p(0)=0.3$，所以，最大后验概率估计需要求极值的部分是：$f(y|\theta)·f(\theta)$

    - 相比极大似然估计，最大后验概率估计多了一个$f(\theta)$

    - 之所以叫最大后验概率估计，因为$P(\theta|y)$就是后验概率

  - 工作流：

    - 定义优化函数$f(y|\theta)·f(\theta)$：$f(y|\theta)$已知，$f(\theta)$如何考虑？**是一种先验概率分布**，总之需要自己去定。可以根据自己的**领域专业知识**认为参数 $\theta$大致服从某种分布，或者直接认为是**均匀分布、高斯分布**。

    - 现在假设参数$\theta$也就是概率p服从正态分布$(\mu,\sigma)$，再进一步假设$\mu=0.5,\sigma=0.1$

    - 最大化的函数：
      $$
      \arg \mathop{\max}\limits_{p}=\frac{1}{0.1\sqrt{2\pi}}e^{-\frac{(p-0.5)^2}{2·0.1^2}}\prod_{i=1}^{n} p^{y_i}(1-p)^{1-y_i}
      $$
      将10个样本数据代入则有：$\arg \mathop{\max}\limits_{p}=p^7(1-p)^3\frac{1}{0.1\sqrt{2\pi}}e^{-\frac{(p-0.5)^2}{2·0.1^2}}$，图示如下：

      ```python
      import numpy as np
      import matplotlib.pyplot as plt
      
      # 定义函数
      def f(p):
          return p**7 * (1 - p)**3 * (1 / (0.1 * np.sqrt(2 * np.pi))) * np.exp(-((p - 0.5)**2) / (2 * 0.1**2))
      
      # 生成一组 p 值
      p_values = np.linspace(0, 1, 1000)
      
      # 计算对应的函数值
      f_values = f(p_values)
      
      # 绘制函数图像
      plt.plot(p_values, f_values, label='f(p)')
      
      # 添加标签和标题
      plt.xlabel('p')
      plt.ylabel('f(p)')
      plt.title('Plot of f(p)')
      
      # 显示图例
      plt.legend()
      
      # 显示图像
      plt.show()
      ```

      

      ![最大后验概率估计图示](..\示例图片\最大后验概率估计图示.png)

    - 估计参数：p=0.55769使得上述表达式最大：0.0049

      ```python
      import numpy as np
      from scipy.optimize import minimize
      
      # 定义负数的 f(p)，因为 minimize 函数寻找最小值
      def negative_f(p):
          return -p**7 * (1 - p)**3 * (1 / (0.1 * np.sqrt(2 * np.pi))) * np.exp(-((p - 0.5)**2) / (2 * 0.1**2))
      
      # 设置初始猜测值
      initial_guess = 0.5
      
      # 使用 minimize 函数找到最大值
      result = minimize(negative_f, initial_guess, bounds=[(0, 1)])
      
      # 最大化的 p 值
      maximized_p = result.x[0]
      maximized_f = -result.fun
      
      print(f"最大化的 p 值：{maximized_p}")
      print(f"对应的最大值 f(p)：{maximized_f}")
      ```

- 补充：**先验概率**和**后验概率**

  - 先验概率

    先验概率是在考虑任何新观测数据之前，基于已有的信息和经验，对随机事件或参数的概率分布的估计。

  - 后验概率

    后验概率是在观测到新数据后，更新了我们对随机事件或参数的概率分布的估计。

### 2.2.2 熵理论Entropy

- 参考：
  1. https://kikaben.com/entropy-demystified/
  2. https://kikaben.com/cross-entropy-demystified/
  3. [一文搞懂熵(Entropy),交叉熵(Cross-Entropy)](https://zhuanlan.zhihu.com/p/149186719?utm_psn=1700704944624132096)
  4. [交叉熵、相对熵（KL散度）、JS散度和Wasserstein距离（推土机距离）](https://zhuanlan.zhihu.com/p/74075915?utm_psn=1700704842182406144)

核心概念是**熵**，两方面理解：

1. **信息**

   事件的信息量，基本观点：**事件发生的概率越小，其信息量越大**。所以定义信息量：
   $$
   I(x)=-log(p(x))
   $$
   其中x是随机变量的取值，**这个概率$p(x)$不等于0，当概率趋近于0，则信息量无穷大。**

   定义**熵是随机变量信息量的期望值**：
   $$
   H(X)=-\sum_{i=1}^{n}p(x_i)log(p(x_i))
   $$

2. **无损编码事件信息（随机变量）的最小平均编码长度**

   **编码**不难理解，就是**文本信息转化为数字信息**。事件信息编码就是编码事件包含的结果。比如天气有：晴天，下雨，吹风，下雪，编码对应：00，01，10，11。

   其中的编码长度就是**数据量大小**，单位是比特(bit)，比如编码00，就是两位编码长度，2bit

   但事件（或者说随机变量）有个特征：**概率**。随机变量每个取值都有对应的概率，当我们对随机变量取值进行编码，所谓**平均编码长度**就是**随机变量取值编码长度的期望**。

   ![熵编码](..\示例图片\熵编码.png)

   比如下面4种天气编码，fine编码长度为1，cloudy编码长度：2，rainy编码长度为3，snow编码长度：3，那么平均编码长度：$60\%*1 + 38\%*2 + 1\%*3 + 1\%*3$

   上面的平均编码长度是最小吗？不知道。那么如何计算**最小平均编码长度**呢？

   一个直觉的想法是，**可能性大的随机变量取值编码长度大，可能性小的编码长度小，这样的平均编码长度会更小。**因为平均编码长度计算涉及概率，大概率乘以较小的数总体会更小。

   这个想法还不够，如何定量给出最小编码方法？这就是**熵的定义**：**随机变量取值的最小平均编码长度**
   $$
   H(X)=-\sum_{i=1}^{n}p(x_i)log(p(x_i))
   $$
   公式已经给出了每个随机变量取值的编码方式：$-log(p(x_i))$，这个公式其实就是代表了这个随机变量取值$x_i$的编码长度是$-log(p(x_i))$，至于怎么编码是任意的，只要每个取值之间的编码不重复即可。话说回来，$-log(p(x_i))$前面是叫**信息量，也是编码长度**，单位是bit

- **交叉熵Cross-Entropy**

  有了熵的计算公式，计算随机变量的熵很简单，但是有一个**前提：随机变量的概率函数已知。**那么假如，我们获得了**随机变量的概率分布的估计，也就是分类模型的输出，**如何**判断估计的概率分布是否接近真实分布**？再看熵计算公式：
  $$
  H(X)=-\sum_{i=1}^{n}p(x_i)log(p(x_i))
  $$
  包含两部分，**一部分是信息量，也就是编码长度，一部分是随机变量概率**。

  现在**定义交叉熵**：
  $$
  H(P,Q)=-\sum_{i=1}^{n}p(x_i)log(q(x_i))
  $$
  其中$p(x_i)$是真实分布，$q(x_i)$是估计模型分布。毫无疑问此时已经不是随机变量X的熵了。**编码长度用估计分布，概率用真实分布计算**。那这个交叉熵$H(p,q)$是什么？和随机变量的熵$H(X)$是什么关系？

  回到**熵的意义：编码随机变量取值的最小平均长度**。那$H(p,q)$是估计分布和真实分布混合交叉的表达式，虽然不知道它是什么，但是因为$H(X)$是最小的，那么就有：
  $$
  H(P,Q)\ge H(x)
  $$
  更进一步，**估计分布$q(x_i)$越接近真实分布$p(x_i)$，$H(p,q)$越接近最小的$H(X)$，$H(p,q)$会越小**

  那其实还有一个问题：**定义交叉熵的时候，取对数的为什么不是真实分布而是估计分布？$H(p,q)=-\sum_{i=1}^{n}q(x_i)log(p(x_i))$有何不可？**

  客观说是可以的，但是要看交叉熵是用来干嘛的，熵是随机变量取值编码的最小平均编码长度，**交叉熵是用来度量真实分布和估计分布的差异，用途主要是机器学习中分类的损失函数**，估计分布$q(x_i)$当然是模型的输出$f(\pmb{x})$，真实分布是训$p(x_i)$练数据中的标签。**对数运算的前提是分布概率不为0**，真实分布中标签为0的意思就是分布概率为0，比如第一个标签[1 0 0 0 0]中$p(dog)=1,p(fox)=f(horse)=p(eagle)=p(squirrel)=0$，概率为0自然不能对数运算。一般情况模型输出$f(\pmb{x})$不会是0，可以对数运算。

  ![分类标签](..\示例图片\分类标签.png)

  再次强调：==通常情况，模型用$f(\pmb{x})$表示，$\pmb{x}$是输入数据(向量)，但概率统计中x是随机变量取值，也就是随机试验的结果。所以常说的分布$p(x)$中的x对应是模型的输出$y=f(\pmb{x})$==

- **kl散度（相对熵）KL Divergence**

  kl散度和交叉熵其实作用是相同的：**度量两个概率分布的相似性**，**kl散度的定义包含了交叉熵和熵：**
  $$
  D_{KL}(P||Q)=H(P,Q)-H(X)=-\sum_{i=1}^{n}p(x_i)log(q(x_i))-(-\sum_{i=1}^{n}p(x_i)log(p(x_i)))
  $$
  相比交叉熵，kl散度多的部分就是**随机变量的熵**。kl散度具有非负性，和交叉熵有相同的逻辑：**估计分布$q(x_i)$越接近真实分布$p(x_i)$，$H(p,q)$越接近最小的$H(X)$，$H(p,q)$会越小，$D_{KL}(P||Q)$也会最小**

- **交叉熵和kl散度作为损失函数**

  机器学习中的损失函数是什么？度量模型输出和真实输出之间的相似性，通过最小化损失函数使模型输出拟合真是输出，在分类模型中就是使模型分类概率分布拟合真实分布

  交叉熵和kl散度正是这也逻辑：

  - 二分类：

    一般真实分类标签是0或者1，假设$P(1)=p,P(0)=1-p$

    交叉熵损失函数：$H(P,Q)=-1*log(q(1))-0*log(q(0))$

  - 多分类

    ![分类标签](..\示例图片\分类标签.png)

    假如训练数据是第一个，真实标签是[1 0 0 0 0]

    交叉熵损失函数：$H(P,Q)=-1*log(q(dog))-0*log(q(fox))-0*log(q(horse))-0*log(q(eagle))-0*log(q(squirrel))$

  - 注意：**目前分类模型的损失函数一般是交叉熵，而不是KL散度。**

    损失函数的功能是通过样本来计算模型分布与目标分布间的差异，在分布差异计算中，KL散度是最合适的。但在实际中，某一事件的标签是已知不变的（例如我们设置猫的label为1，那么所有关于猫的样本都要标记为1），即**目标分布的熵为常数**。而根据下面KL公式可以看到，KL散度 - 目标分布熵 = 交叉熵（这里的“-”表示裁剪）。所以我们不用计算KL散度，只需要计算交叉熵就可以得到模型分布与目标分布的损失值。

    但是如果目标分布是有变化的（如同为猫的样本，不同的样本，其值也会有差异），那么就不能使用交叉熵，**例如蒸馏模型的损失函数就是KL散度**。因为蒸馏模型的目标分布也是一个模型，该模型针对同类别的不同样本，会给出不同的预测值（如两张猫的图片a和b，目标模型对a预测为猫的值是0.6，对b预测为猫的值是0.8）。

    **变分自编码器VAE（Variational Auto-encoder）**损失函数也是kl散度

### 2.2.3 Cross Entropy loss

$$
L_{Cross Entropy}(f(\pmb{x}),y) = \sum_{i=1}^{n}y_ilog(f(\pmb{x_i}))
$$

- n表示n个分类
- **可微、连续、凸性**

### 2.2.4 Kullback-Leibler divergence

$$
L_{KL}(f(\pmb{x}),y) = -\sum_{i=1}^{n}y_ilog(f(\pmb{x})_i))-(-\sum_{i=1}^{n}y_ilog(y_i)))
$$

- **可微、连续、凸性**

# 3. Ranking

# 4. sample generation

# 5. Energy-based models

 

