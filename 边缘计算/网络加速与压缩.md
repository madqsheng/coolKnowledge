# 概述

参考：

1. [模型压缩加速](https://www.zhihu.com/question/383341796/answer/1117142111)
2. [模型压缩加速就业](https://www.zhihu.com/question/349948366/answer/2618737660)

模型的**压缩和加速**，本质是寻求**高效的深度学习模型**。压缩和加速并不割裂，两者相辅相成。模型压可能会取得加速，加速可能带来一些模型压缩。

从算法层面，模型加速压缩技术有五中思路：

- 低秩分解
- 剪枝
- 量化
- 知识蒸馏
- 轻量化模型设计

# 1. 低秩分解

[【分布式训练技术分享三】聊聊 Hugging face 模型 + LoRA 低秩矩阵分解的使用 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/628232317)

[SVD和低秩矩阵近似（Low-rank Matrix Approximation）的数据压缩 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/447385674)

- 概述

  - **Low-Rank Decomposition**或者 **Low-Rank Factorization**
  - 一种矩阵分解技术，本质是**将一个大的矩阵分解成几个较小秩的矩阵的乘积**
  - 结果就是**有效地降低矩阵的维度**，提高计算和存储效率，在某些情况下帮助**捕捉数据的主要特征**。
  - 在模型加速领域，**分解的对象是：模型参数**。例如：**卷积层是四维矩阵**，**全连接层是二维矩阵**。

  注意：*卷积层从来都是四维矩阵，全连接层是二维矩阵，这对于理解它们很关键*

  ![cnn过程](..\示例图片\cnn过程.gif)

  ![全连接层](..\示例图片\全连接层.png)

  - 卷积
    - **每个卷积核是三维**的，对应了输入的通道数目。卷积计算以后再相加，得到一个**2维输出**。
    - **卷积数目是卷积层第四维**，**输出数目是feature map的第三维**。
    - 卷积层是四维：(**output channels，input channels，height，width**)，**维数跟输入输出无关**。
    - 卷积输出的特征图feature map三维：(**channels，height，width**)，不过深度学习训练一般是批次训练，所以feature map实际是四维：(**batch，channels，height，width**)
  - 全连接层
    - **全连接算法本质是二维矩阵之间的矩阵乘法**
    - 全连接层可以看成**单层的MLP**(Multilayer Perceptron多层感知机)
    - 全连接层是**二维矩阵**，**维数跟输入输出无关**
    - 如果不看输入输出批次，输入输出是**行向量**

## 1.1 SVD分解

- 概述
  - Singular Value Decomposition奇异值分解
  - 基于奇异值的低秩分解

### 1.1.1 简单回顾线性代数

- 


## 1.2 Tucker 分解

# 2. 剪枝

# 3. 量化

# 4. 知识蒸馏

# 5. 轻量化模型设计

动机：

矩阵的数据，不想存储所有数据，怎么办？

想以某种方式进行数据压缩怎么办