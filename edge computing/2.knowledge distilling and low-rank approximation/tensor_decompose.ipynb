{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac, partial_tucker\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from VBMF import VBMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD\n",
    "参考：https://zhuanlan.zhihu.com/p/42777652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:  (11, 5)\n",
      "sigmaK:  (5, 5)\n",
      "V:  (5, 11)\n",
      "itemMat:  (11, 5)\n",
      "[[-6.35987013e-02 -1.75000038e-01 -2.11189866e-01  6.63243807e-02\n",
      "  -8.38366511e-03  3.94935046e+00 -7.54167361e-03  1.87194064e-01\n",
      "   2.19645050e-01 -3.63779257e-03  5.00657873e+00]\n",
      " [ 3.69312900e-03  4.23362282e-02  5.42305142e-02  3.10727215e+00\n",
      "   1.16611626e-02  3.65499402e+00 -1.49379599e-02 -4.14369054e-02\n",
      "  -7.16127377e-02 -8.41207652e-03  3.27922702e+00]\n",
      " [ 1.53123341e-01  1.21783621e-01  1.57541798e-01 -4.12181011e-02\n",
      "   4.19151330e+00  7.34300163e-03  3.53701064e-02  4.31482341e-01\n",
      "   1.63228657e-01  3.83012245e+00  2.19472453e-02]\n",
      " [ 2.81884646e+00  2.28120460e+00  2.94905331e+00  2.61664828e-01\n",
      "  -2.84987225e-02 -1.29973230e-01 -2.52257574e-02  2.87537670e+00\n",
      "   2.90863719e+00 -2.92679341e-02 -4.53969065e-02]\n",
      " [ 4.87540590e+00  3.92479612e+00  5.07578890e+00  7.21898915e-02\n",
      "  -2.02526648e-03 -1.86878944e-01 -1.12568960e-02  5.01377306e+00\n",
      "   5.07653945e+00  2.08579249e-03  1.41553672e-01]\n",
      " [-6.86636747e-02 -6.04234175e-02 -7.82104374e-02  2.44525321e-02\n",
      "   5.10158954e+00 -1.96629677e-02  1.02682333e+00  2.54358496e-01\n",
      "  -6.13365033e-02  4.87070806e+00  2.20058179e-03]\n",
      " [ 4.28395737e+00  3.41918661e+00  4.42507663e+00 -2.18660190e-01\n",
      "   1.15416566e-02  2.99181674e-01  2.27261041e-02  4.46285946e+00\n",
      "   4.52721401e+00  2.36218917e-02  8.43978644e-01]\n",
      " [ 1.87804940e-02  7.19015110e-02  9.13763816e-02  3.87405311e+00\n",
      "   9.05688704e-03  4.30650304e+00  2.03651811e-02 -5.37877396e-02\n",
      "  -9.23986496e-02 -7.53780635e-03  3.77260042e+00]\n",
      " [ 1.03983780e-02  1.57937469e-03  2.38546880e-03  1.99963140e+00\n",
      "  -2.58711859e-02  1.99943357e+00  4.99298135e+00 -3.75416626e-02\n",
      "   2.34004262e-02  1.03103592e+00  2.00108534e+00]\n",
      " [-6.37071390e-02 -4.87979318e-02 -6.34139202e-02  1.24156817e-02\n",
      "   4.71970589e+00  1.33075997e-02 -6.06726979e-02  2.36894226e-01\n",
      "  -7.10914539e-02  4.29058463e+00 -2.19399789e-02]\n",
      " [ 8.38954613e-01  6.65694286e-01  8.61833890e-01 -1.64305060e-01\n",
      "   9.51682109e-05 -1.61158432e-02  2.43855511e-02  8.80153985e-01\n",
      "   8.94953657e-01  7.63208456e-03  1.25469767e-01]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import svd\n",
    "import numpy as np\n",
    "\n",
    "# 根据我们设置的百分比计算出最少需要的奇异值的数量\n",
    "def select_K(sigma, percentage):\n",
    "    square = sigma**2 \n",
    "    base = sum(square) \n",
    "    s = 0 \n",
    "    k = 0\n",
    "    for i in sigma:\n",
    "        s += i**2\n",
    "        k += 1\n",
    "        if s >= base * percentage:\n",
    "            return k\n",
    "\n",
    "data = np.array([[0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5],\n",
    "           [0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 3],\n",
    "           [0, 0, 0, 0, 4, 0, 0, 1, 0, 4, 0],\n",
    "           [3, 3, 4, 0, 0, 0, 0, 2, 2, 0, 0],\n",
    "           [5, 4, 5, 0, 0, 0, 0, 5, 5, 0, 0],\n",
    "           [0, 0, 0, 0, 5, 0, 1, 0, 0, 5, 0],\n",
    "           [4, 3, 4, 0, 0, 0, 0, 5, 5, 0, 1],\n",
    "           [0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4],\n",
    "           [0, 0, 0, 2, 0, 2, 5, 0, 0, 1, 2],\n",
    "           [0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0],\n",
    "           [1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]])\n",
    "\n",
    "u, sigma, v = svd(data)\n",
    "'''\n",
    "这里得到的\n",
    "U和v是左右奇异向量矩阵\n",
    "sigma是奇异值列表，并且从大到小排序\n",
    "如果data的尺寸是m*n\n",
    "那么，\n",
    "U尺寸是m*m\n",
    "V尺寸是n*n\n",
    "'''\n",
    "\n",
    "#找出压缩的奇异值数量\n",
    "k = select_K(sigma, 0.98) # 5\n",
    "sigmaK = np.mat(np.eye(k) * sigma[:k]) \n",
    "\n",
    "# 最后压缩之后得到的是item的矩阵，其中的每一个行向量对应一个item。\n",
    "itemMat = np.matmul(np.matmul(data.T,u[:,:k]), sigmaK.I)\n",
    "print(\"U: \", u[:,:k].shape)\n",
    "print(\"sigmaK: \", sigmaK.shape)\n",
    "print(\"V: \", v[:k,:].shape)\n",
    "print(\"itemMat: \",itemMat.shape)\n",
    "#==========================================================\n",
    "\n",
    "# 重建数据\n",
    "# data_compress=u[:, :k] * sigma[:k] @ v[:k, :]\n",
    "data_compress = u[:, :k] @ sigmaK @ v[:k, :]\n",
    "print(data_compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight,factors = tl.decomposition.parafac(randint_tensor, rank=rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69.73197575 -1.65361332 -4.96177232 -0.5023591   3.34929773]\n",
      " [75.08698228 -2.76731812 -1.09477499  3.25216814  0.55126361]\n",
      " [71.78454884  0.10877523  1.44494359  2.72581091  1.34335892]\n",
      " [72.38644068 -5.85877685 -1.63931796 -0.54552514  3.13910576]] (4, 5)\n",
      "[[ 0.45476539 -0.09749693 -0.65080847  0.41220718  0.31728844]\n",
      " [ 0.4376696   0.65803641  0.24957269 -0.60565502  0.8189591 ]\n",
      " [ 0.47142717  0.88353733 -0.26320738 -0.12378585 -0.71448683]\n",
      " [ 0.44776154 -0.23253811  0.64680698  0.50702296  0.44195478]\n",
      " [ 0.41076839 -0.03321074  0.90737748  0.89789492  1.76992413]] (5, 5)\n",
      "[[ 0.40994823 -0.87027073  0.19115964 -0.92631294  0.77614502]\n",
      " [ 0.42130478 -1.08900854  0.61445631 -1.06850321 -0.14368451]\n",
      " [ 0.36650137 -0.22304109  1.06141629  1.00004339  0.64244921]\n",
      " [ 0.4050568  -0.30503273  1.14770903  0.68642186 -0.11907894]\n",
      " [ 0.41537085  0.65192425  0.20687916 -0.23592464  0.61394999]\n",
      " [ 0.42873761 -1.22519892 -0.10441571  0.13504315  0.29708115]] (6, 5)\n",
      "[[ 0.33901505  0.61893537 -0.10567071 -0.73854861  0.73101783]\n",
      " [ 0.33984506 -0.2380399  -0.13218846  0.76438617  1.11813018]\n",
      " [ 0.39945743 -0.19558836  0.55901296  0.34025724  0.32741917]\n",
      " [ 0.39426303 -0.43745206  0.39541594 -0.36130354 -0.10070427]\n",
      " [ 0.3820025   0.28302496 -0.53292926  0.24862747 -0.13450105]\n",
      " [ 0.38404155 -0.15548074 -0.88655542  1.06598966 -0.10967071]\n",
      " [ 0.36754131 -0.67387194 -0.05262474 -0.68994591  0.27374655]] (7, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "\n",
    "# 创建一个形状为 (2, 3) 的随机整数数组，在 [low, high) 范围内\n",
    "randint_tensor = np.random.randint(low=1, high=10, size=(4, 5,6,7))\n",
    "# print(randint_tensor)\n",
    "\n",
    "# 执行CP分解，假设分解的秩为2\n",
    "weight,factors = tl.decomposition.parafac(randint_tensor, rank=5)\n",
    "\n",
    "# 打印分解得到的因子\n",
    "for factor in factors:\n",
    "    print(factor,factor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cp分解的api：tl.decomposition.parafac\n",
    "外积重建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n",
      "原始张量与重建张量的差异：7.62643178862702\n",
      "原始张量的形状： (4, 5, 6, 7)\n",
      "重建张量的形状： (4, 5, 6, 7)\n",
      "原始张量与重建张量的差异：7.62643178862702\n",
      "原始张量的形状： (4, 5, 6, 7)\n",
      "重建张量的形状： (4, 5, 6, 7)\n"
     ]
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个示例四维张量\n",
    "tensor_shape = (4,5,6,7)\n",
    "original_tensor = np.random.rand(*tensor_shape)\n",
    "\n",
    "# 执行CP分解，假设分解的秩为2\n",
    "rank = 4\n",
    "weight,factors = tl.decomposition.parafac(original_tensor, rank=rank)\n",
    "print(weight)\n",
    "\n",
    "#=============================================================================\n",
    "# 重建张量\n",
    "reconstructed_tensor = tl.cp_to_tensor((weight,factors))\n",
    "\n",
    "# 计算原始张量与重建张量的差异\n",
    "difference = np.linalg.norm(original_tensor - reconstructed_tensor)\n",
    "\n",
    "# 打印差异\n",
    "print(f\"原始张量与重建张量的差异：{difference}\")\n",
    "\n",
    "# 打印原始张量和重建张量的形状\n",
    "print(\"原始张量的形状：\", original_tensor.shape)\n",
    "print(\"重建张量的形状：\", reconstructed_tensor.shape)\n",
    "\n",
    "\n",
    "# 手动重建张量\n",
    "reconstructed_tensor = np.zeros(tensor_shape)\n",
    "for i in range(rank):\n",
    "    # last_two=np.outer(factors[2][:, i], factors[3][:, i])\n",
    "    # last_three=np.outer(factors[1][:, i],last_two)\n",
    "    # last=np.outer(factors[0][:, i],last_three).reshape(factors[0].shape[0],factors[1].shape[0],factors[2].shape[0],factors[3].shape[0])\n",
    "\n",
    "    # 对每个模式的因子进行外积\n",
    "    factor_product = np.outer(factors[0][:, i], np.outer(factors[1][:, i], np.outer(factors[2][:, i], factors[3][:, i]))).reshape(factors[0].shape[0],factors[1].shape[0],factors[2].shape[0],factors[3].shape[0])\n",
    "    # 累加到重建张量\n",
    "    reconstructed_tensor += factor_product\n",
    "\n",
    "# 计算原始张量与重建张量的差异\n",
    "difference = np.linalg.norm(original_tensor - reconstructed_tensor)\n",
    "\n",
    "# 打印差异\n",
    "print(f\"原始张量与重建张量的差异：{difference}\")\n",
    "\n",
    "# 打印原始张量和重建张量的形状\n",
    "print(\"原始张量的形状：\", original_tensor.shape)\n",
    "print(\"重建张量的形状：\", reconstructed_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量的Kruskal 形式  \n",
    "\n",
    "Matrix可以表示为两个向量的外积和，三阶张量表示为三个向量的外积和,  $N$ 阶段张量可以表示为N个向量的外积和. 和的个数表示为张量的 Kruskal 秩.  \n",
    "\n",
    "![kruskal_tensor](../../示例图片/triplets.png)  \n",
    "\n",
    "\n",
    "## 获得 Kruskal 表示: CP 分解  \n",
    "使用CP对张量进行秩 $R$ 分解.  \n",
    "\n",
    "在TensorLy库中只需要简单调用函数 **parafac**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "import torch\n",
    "\n",
    "# 分解卷积矩阵\n",
    "def cp_decomposition_conv_layer(layer, rank):\n",
    "    \"\"\" Gets a conv layer and a target rank, \n",
    "        returns a nn.Sequential object with the decomposition \"\"\"\n",
    "\n",
    "    # Perform CP decomposition on the layer weight tensorly. \n",
    "    # last, first, vertical, horizontal = \\\n",
    "    weight, (last, first, vertical, horizontal) = \\\n",
    "        tl.decomposition.parafac(layer.weight.data.numpy(), rank=rank, init='svd')\n",
    "\n",
    "    # print(weight)\n",
    "    \n",
    "    print('conv2d layer shape: ',layer.weight.data.numpy().shape)\n",
    "    print('rank: ', rank)\n",
    "\n",
    "    print('first shape: ',first.shape)\n",
    "    print('vertical shape: ',vertical.shape)\n",
    "    print('horizontal shape: ',horizontal.shape)\n",
    "    print('last shape: ',last.shape)\n",
    "\n",
    "    pointwise_s_to_r_layer = torch.nn.Conv2d(\n",
    "        in_channels=first.shape[0],\n",
    "        out_channels=first.shape[1], \n",
    "        kernel_size=1, \n",
    "        stride=1, \n",
    "        padding=0, \n",
    "        dilation=layer.dilation, \n",
    "        bias=False\n",
    "        )\n",
    "\n",
    "    depthwise_vertical_layer = torch.nn.Conv2d(\n",
    "        in_channels=vertical.shape[1], \n",
    "        out_channels=vertical.shape[1], \n",
    "        kernel_size=(vertical.shape[0], 1),\n",
    "        stride=1, \n",
    "        padding=(layer.padding[0], 0), \n",
    "        dilation=layer.dilation,groups=vertical.shape[1], \n",
    "        bias=False\n",
    "        )\n",
    "\n",
    "    depthwise_horizontal_layer = torch.nn.Conv2d(\n",
    "        in_channels=horizontal.shape[1], \n",
    "        out_channels=horizontal.shape[1], \n",
    "        kernel_size=(1, horizontal.shape[0]), \n",
    "        stride=layer.stride,\n",
    "        padding=(0, layer.padding[0]), \n",
    "        dilation=layer.dilation, \n",
    "        groups=horizontal.shape[1], \n",
    "        bias=False\n",
    "        )\n",
    "\n",
    "    pointwise_r_to_t_layer = torch.nn.Conv2d(\n",
    "        in_channels=last.shape[1], \n",
    "        out_channels=last.shape[0], \n",
    "        kernel_size=1, \n",
    "        stride=1,\n",
    "        padding=0, \n",
    "        dilation=layer.dilation, \n",
    "        bias=True\n",
    "        )\n",
    "\n",
    "    print('pointwise_s_to_r_layer shape: ', pointwise_s_to_r_layer.weight.data.numpy().shape)\n",
    "    print('depthwise_vertical_layer shape: ', depthwise_vertical_layer.weight.data.numpy().shape)\n",
    "    print('depthwise_horizontal_layer shape: ', depthwise_horizontal_layer.weight.data.numpy().shape)\n",
    "    print('pointwise_r_to_t_layer shape: ', pointwise_r_to_t_layer.weight.data.numpy().shape)\n",
    "    print('################################################################')\n",
    "\n",
    "    pointwise_r_to_t_layer.bias.data = layer.bias.data\n",
    "\n",
    "    #这里给每个层的参数提供数据，来自cp分解的因子\n",
    "    #(last, first, vertical, horizontal)对应(kernel_nums,channel_nums,higth_kernel_size,width_kernel_size)\n",
    "    depthwise_horizontal_layer.weight.data = torch.transpose(torch.tensor(horizontal), 1, 0).unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "    depthwise_vertical_layer.weight.data = torch.transpose(torch.tensor(vertical), 1, 0).unsqueeze(1).unsqueeze(-1)\n",
    "\n",
    "    pointwise_s_to_r_layer.weight.data = torch.transpose(torch.tensor(first), 1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    pointwise_r_to_t_layer.weight.data = torch.tensor(last).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    new_layers = [pointwise_s_to_r_layer, depthwise_vertical_layer, depthwise_horizontal_layer, pointwise_r_to_t_layer]\n",
    "    \n",
    "    return nn.Sequential(*new_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_ranks(layer):\n",
    "    \"\"\" Unfold the 2 modes of the Tensor the decomposition will \n",
    "    be performed on, and estimates the ranks of the matrices using VBMF \n",
    "    \"\"\"\n",
    "\n",
    "    weights = layer.weight.data\n",
    "    unfold_0 = tl.base.unfold(weights.numpy(), 0) \n",
    "    unfold_1 = tl.base.unfold(weights.numpy(), 1)\n",
    "    _, diag_0, _, _ = VBMF.EVBMF(unfold_0)\n",
    "    _, diag_1, _, _ = VBMF.EVBMF(unfold_1)\n",
    "    ranks = [diag_0.shape[0], diag_1.shape[1]]\n",
    "    return ranks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker 分解\n",
    "\n",
    "Tucker 分解可以看成CP分解的一般形式. 在卷积中实际只要对ic/oc进行分解即可，相当于Trucker分解有用的性质是，它不必沿着所有的轴（模）来分解。我们可以沿着输入和输出通道进行分解（模2的分解） \n",
    "\n",
    "![tucker_tensor](../../示例图片/tucker.png)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tucker_decomposition_conv_layer(layer):\n",
    "    \"\"\" Gets a conv layer, \n",
    "        returns a nn.Sequential object with the Tucker decomposition.\n",
    "        The ranks are estimated with a Python implementation of VBMF\n",
    "        https://github.com/CasvandenBogaard/VBMF\n",
    "    \"\"\"\n",
    "\n",
    "    print('conv2d layer shape: ',layer.weight.data.numpy().shape)\n",
    "    ranks = estimate_ranks(layer)\n",
    "    print(layer, \"VBMF Estimated ranks\", ranks)\n",
    "    core, [last, first] = \\\n",
    "        partial_tucker(layer.weight.data.numpy(), \\\n",
    "            modes=[0, 1], rank=ranks, init='svd')\n",
    "\n",
    "    print('first shape: ',first.shape)\n",
    "    print('core shape: ',core.shape)\n",
    "    print('last shape: ',last.shape)\n",
    "\n",
    "    # A pointwise convolution that reduces the channels from S to R3\n",
    "    first_layer = torch.nn.Conv2d(in_channels=first.shape[0], \\\n",
    "            out_channels=first.shape[1], kernel_size=1,\n",
    "            stride=1, padding=0, dilation=layer.dilation, bias=False)\n",
    "\n",
    "    # A regular 2D convolution layer with R3 input channels \n",
    "    # and R3 output channels\n",
    "    core_layer = torch.nn.Conv2d(in_channels=core.shape[1], \\\n",
    "            out_channels=core.shape[0], kernel_size=layer.kernel_size,\n",
    "            stride=layer.stride, padding=layer.padding, dilation=layer.dilation,\n",
    "            bias=False)\n",
    "\n",
    "    # A pointwise convolution that increases the channels from R4 to T\n",
    "    last_layer = torch.nn.Conv2d(in_channels=last.shape[1], \\\n",
    "        out_channels=last.shape[0], kernel_size=1, stride=1,\n",
    "        padding=0, dilation=layer.dilation, bias=True)\n",
    "\n",
    "    print('first_layer shape: ', first_layer.weight.data.numpy().shape)\n",
    "    print('core_layer shape: ', core_layer.weight.data.numpy().shape)\n",
    "    print('last_layer shape: ', last_layer.weight.data.numpy().shape)\n",
    "    print('################################################################')\n",
    "\n",
    "    last_layer.bias.data = layer.bias.data\n",
    "\n",
    "    first_layer.weight.data = \\\n",
    "        torch.transpose(torch.tensor(first.copy()), 1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "    last_layer.weight.data = torch.tensor(last.copy()).unsqueeze(-1).unsqueeze(-1)\n",
    "    core_layer.weight.data = torch.tensor(core.copy())\n",
    "\n",
    "    new_layers = [first_layer, core_layer, last_layer]\n",
    "    return nn.Sequential(*new_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VGG16 based network for classifying between dogs and cats.\n",
    "# After training this will be an over parameterized network,\n",
    "# with potential to shrink it.\n",
    "class ModifiedVGG16Model(torch.nn.Module):\n",
    "    def __init__(self, model=None):\n",
    "        super(ModifiedVGG16Model, self).__init__()\n",
    "\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        self.features = model.features\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(9216, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.25, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "conv2d layer shape:  (32, 1, 3, 3)\n",
      "rank:  10\n",
      "first shape:  (1, 10)\n",
      "vertical shape:  (3, 10)\n",
      "horizontal shape:  (3, 10)\n",
      "last shape:  (32, 10)\n",
      "pointwise_s_to_r_layer shape:  (10, 1, 1, 1)\n",
      "depthwise_vertical_layer shape:  (10, 1, 3, 1)\n",
      "depthwise_horizontal_layer shape:  (10, 1, 1, 3)\n",
      "pointwise_r_to_t_layer shape:  (32, 10, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (64, 32, 3, 3)\n",
      "rank:  21\n",
      "first shape:  (32, 21)\n",
      "vertical shape:  (3, 21)\n",
      "horizontal shape:  (3, 21)\n",
      "last shape:  (64, 21)\n",
      "pointwise_s_to_r_layer shape:  (21, 32, 1, 1)\n",
      "depthwise_vertical_layer shape:  (21, 1, 3, 1)\n",
      "depthwise_horizontal_layer shape:  (21, 1, 1, 3)\n",
      "pointwise_r_to_t_layer shape:  (64, 21, 1, 1)\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"/home/huan.wang/lessons/fastai-course/chapter2/mnist_model\").cuda()\n",
    "print(model)\n",
    "model.eval()\n",
    "model.cpu()\n",
    "N = len(model.features._modules.keys())\n",
    "for i, key in enumerate(model.features._modules.keys()):\n",
    "    if i >= N - 2: # 后续fc层\n",
    "        break\n",
    "    if isinstance(model.features._modules[key], torch.nn.modules.conv.Conv2d):\n",
    "        conv_layer = model.features._modules[key]\n",
    "        rank = max(conv_layer.weight.data.numpy().shape)//3\n",
    "        decomposed = cp_decomposition_conv_layer(conv_layer, rank)\n",
    "        model.features._modules[key] = decomposed\n",
    "\n",
    "torch.save(model, 'decomposed_mnist_model_cp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModifiedVGG16Model(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "conv2d layer shape:  (64, 3, 3, 3)\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [14, 2]\n",
      "first shape:  (3, 2)\n",
      "core shape:  (14, 2, 3, 3)\n",
      "last shape:  (64, 14)\n",
      "first_layer shape:  (2, 3, 1, 1)\n",
      "core_layer shape:  (14, 2, 3, 3)\n",
      "last_layer shape:  (64, 14, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (64, 64, 3, 3)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [26, 29]\n",
      "first shape:  (64, 29)\n",
      "core shape:  (26, 29, 3, 3)\n",
      "last shape:  (64, 26)\n",
      "first_layer shape:  (29, 64, 1, 1)\n",
      "core_layer shape:  (26, 29, 3, 3)\n",
      "last_layer shape:  (64, 26, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (128, 64, 3, 3)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [39, 32]\n",
      "first shape:  (64, 32)\n",
      "core shape:  (39, 32, 3, 3)\n",
      "last shape:  (128, 39)\n",
      "first_layer shape:  (32, 64, 1, 1)\n",
      "core_layer shape:  (39, 32, 3, 3)\n",
      "last_layer shape:  (128, 39, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (128, 128, 3, 3)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [42, 43]\n",
      "first shape:  (128, 43)\n",
      "core shape:  (42, 43, 3, 3)\n",
      "last shape:  (128, 42)\n",
      "first_layer shape:  (43, 128, 1, 1)\n",
      "core_layer shape:  (42, 43, 3, 3)\n",
      "last_layer shape:  (128, 42, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (256, 128, 3, 3)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [71, 59]\n",
      "first shape:  (128, 59)\n",
      "core shape:  (71, 59, 3, 3)\n",
      "last shape:  (256, 71)\n",
      "first_layer shape:  (59, 128, 1, 1)\n",
      "core_layer shape:  (71, 59, 3, 3)\n",
      "last_layer shape:  (256, 71, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (256, 256, 3, 3)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [78, 81]\n",
      "first shape:  (256, 81)\n",
      "core shape:  (78, 81, 3, 3)\n",
      "last shape:  (256, 78)\n",
      "first_layer shape:  (81, 256, 1, 1)\n",
      "core_layer shape:  (78, 81, 3, 3)\n",
      "last_layer shape:  (256, 78, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (256, 256, 3, 3)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [70, 73]\n",
      "first shape:  (256, 73)\n",
      "core shape:  (70, 73, 3, 3)\n",
      "last shape:  (256, 70)\n",
      "first_layer shape:  (73, 256, 1, 1)\n",
      "core_layer shape:  (70, 73, 3, 3)\n",
      "last_layer shape:  (256, 70, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (512, 256, 3, 3)\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [131, 110]\n",
      "first shape:  (256, 110)\n",
      "core shape:  (131, 110, 3, 3)\n",
      "last shape:  (512, 131)\n",
      "first_layer shape:  (110, 256, 1, 1)\n",
      "core_layer shape:  (131, 110, 3, 3)\n",
      "last_layer shape:  (512, 131, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (512, 512, 3, 3)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [138, 148]\n",
      "first shape:  (512, 148)\n",
      "core shape:  (138, 148, 3, 3)\n",
      "last shape:  (512, 138)\n",
      "first_layer shape:  (148, 512, 1, 1)\n",
      "core_layer shape:  (138, 148, 3, 3)\n",
      "last_layer shape:  (512, 138, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (512, 512, 3, 3)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [121, 132]\n",
      "first shape:  (512, 132)\n",
      "core shape:  (121, 132, 3, 3)\n",
      "last shape:  (512, 121)\n",
      "first_layer shape:  (132, 512, 1, 1)\n",
      "core_layer shape:  (121, 132, 3, 3)\n",
      "last_layer shape:  (512, 121, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (512, 512, 3, 3)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [144, 157]\n",
      "first shape:  (512, 157)\n",
      "core shape:  (144, 157, 3, 3)\n",
      "last shape:  (512, 144)\n",
      "first_layer shape:  (157, 512, 1, 1)\n",
      "core_layer shape:  (144, 157, 3, 3)\n",
      "last_layer shape:  (512, 144, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (512, 512, 3, 3)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [147, 149]\n",
      "first shape:  (512, 149)\n",
      "core shape:  (147, 149, 3, 3)\n",
      "last shape:  (512, 147)\n",
      "first_layer shape:  (149, 512, 1, 1)\n",
      "core_layer shape:  (147, 149, 3, 3)\n",
      "last_layer shape:  (512, 147, 1, 1)\n",
      "################################################################\n",
      "conv2d layer shape:  (512, 512, 3, 3)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) VBMF Estimated ranks [152, 155]\n",
      "first shape:  (512, 155)\n",
      "core shape:  (152, 155, 3, 3)\n",
      "last shape:  (512, 152)\n",
      "first_layer shape:  (155, 512, 1, 1)\n",
      "core_layer shape:  (152, 155, 3, 3)\n",
      "last_layer shape:  (512, 152, 1, 1)\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"/home/huan.wang/lessons/fastai-course/chapter2/vgg_model\").cuda()\n",
    "print(model)\n",
    "model.eval()\n",
    "model.cpu()\n",
    "N = len(model.features._modules.keys())\n",
    "for i, key in enumerate(model.features._modules.keys()):\n",
    "    if i >= N - 2: # 后续fc层\n",
    "        break\n",
    "    if isinstance(model.features._modules[key], torch.nn.modules.conv.Conv2d):\n",
    "        conv_layer = model.features._modules[key]\n",
    "        decomposed = tucker_decomposition_conv_layer(conv_layer)\n",
    "        model.features._modules[key] = decomposed\n",
    "\n",
    "torch.save(model, 'decomposed_vgg_model_tucker')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374fbd2ee474b3c2e2c20a4c8f0e793d15fc8310f93cfe7d25a3e012a639abbc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
